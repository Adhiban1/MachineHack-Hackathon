{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "beb77623",
      "metadata": {
        "id": "beb77623"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.svm import SVR\n",
        "from zipfile import ZipFile\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import Sequential\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0NSNDpMRAJy",
        "outputId": "8996bd43-f299-4d7d-c2d7-8e89881f671a"
      },
      "id": "g0NSNDpMRAJy",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7f7f0303",
      "metadata": {
        "id": "7f7f0303"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('dataset'):\n",
        "    with ZipFile('/content/drive/MyDrive/Colab Notebooks/Hackathons/Hackathon_2/Participants_Data_GGSH_Solution_Notebook.zip') as f:\n",
        "        f.extractall('dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a6430a5d",
      "metadata": {
        "id": "a6430a5d"
      },
      "outputs": [],
      "source": [
        "def leaderboard():\n",
        "    with open('leaderboard.txt') as f:\n",
        "        data = f.read()\n",
        "    data = re.findall('[\\d]+\\.([\\d]+.[\\d]+)', data)\n",
        "    return [float(i[5:]) for i in data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "fd468436",
      "metadata": {
        "id": "fd468436"
      },
      "outputs": [],
      "source": [
        "india_train = pd.read_csv('dataset/India_train.csv')\n",
        "india_test = pd.read_csv('dataset/India_test.csv')\n",
        "USA_train = pd.read_csv('dataset/USA_train.csv')\n",
        "USA_test = pd.read_csv('dataset/USA_test.csv')\n",
        "India_soil_rainfall_30years = pd.read_csv('dataset/India_soil_rainfall_30years.csv')\n",
        "USA_Commodity_prices = pd.read_csv('dataset/USA_Commodity_prices.csv')\n",
        "submission = pd.read_csv('dataset/submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e7f59883",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7f59883",
        "outputId": "2c8ce30d-cef0-4c9f-a71c-7ed094d857d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yield (Pounds/ Harvested Area) | USA\n",
            "COTTON YIELD (Kg per ha) | India\n",
            "Cotton_Price[Dollar/ton] | USA_Commodity_prices\n"
          ]
        }
      ],
      "source": [
        "for i in submission.columns:\n",
        "    print(i, end='')\n",
        "    if i in india_test.columns:\n",
        "        print(' | India')\n",
        "    if i in USA_train.columns:\n",
        "        print(' | USA')\n",
        "    if i in India_soil_rainfall_30years.columns:\n",
        "        print(' | India_soil_rainfall_30years')\n",
        "    if i in USA_Commodity_prices.columns:\n",
        "        print(' | USA_Commodity_prices')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5ed3eb9",
      "metadata": {
        "id": "b5ed3eb9"
      },
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8b127eb8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b127eb8",
        "outputId": "e7867b93-d17a-4727-dafd-a3bb27c537d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([dtype('int64'), dtype('O'), dtype('float64')], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "india_train.dtypes.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "182f36e3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "182f36e3",
        "outputId": "02d33974-c7bd-4579-bf66-ed9a37aa9ba5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['State Name', 'Dist Name'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "india_train.select_dtypes('object').columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0a766d0b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "0a766d0b",
        "outputId": "8d58264b-fc7b-4670-d07a-0881840d6bd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Year  COTTON AREA (1000 ha)  COTTON PRODUCTION (1000 tons)  \\\n",
              "0  1990                    0.0                            0.0   \n",
              "1  1990                    7.0                            3.0   \n",
              "2  1990                   49.0                          238.0   \n",
              "3  1990                   26.0                          120.0   \n",
              "4  1990                  996.0                          289.0   \n",
              "\n",
              "   COTTON YIELD (Kg per ha)  JANUARY PERCIPITATION (Millimeters)  \\\n",
              "0                         0                                 4.05   \n",
              "1                      3333                                  NaN   \n",
              "2                      4944                                 3.28   \n",
              "3                      4964                                 4.14   \n",
              "4                      2892                                 1.18   \n",
              "\n",
              "   FEBRUARY PERCIPITATION (Millimeters)  MARCH PERCIPITATION (Millimeters)  \\\n",
              "0                                 50.75                              75.34   \n",
              "1                                 54.03                              94.67   \n",
              "2                                 39.90                              68.64   \n",
              "3                                 43.94                              48.83   \n",
              "4                                   NaN                              32.47   \n",
              "\n",
              "   APRIL PERCIPITATION (Millimeters)  MAY PERCIPITATION (Millimeters)  \\\n",
              "0                              18.87                            57.59   \n",
              "1                              12.21                           143.97   \n",
              "2                               8.12                           207.71   \n",
              "3                               5.39                           230.23   \n",
              "4                               2.26                           236.77   \n",
              "\n",
              "   JUNE PERCIPITATION (Millimeters)  ...  PHOSPHATE SHARE IN NPK (Percent)  \\\n",
              "0                            123.74  ...                             23.32   \n",
              "1                            115.08  ...                             18.24   \n",
              "2                            131.98  ...                             19.69   \n",
              "3                            146.55  ...                               NaN   \n",
              "4                               NaN  ...                             28.12   \n",
              "\n",
              "   PHOSPHATE PER HA OF NCA (Kg per ha)  PHOSPHATE PER HA OF GCA (Kg per ha)  \\\n",
              "0                                19.79                                15.90   \n",
              "1                                15.43                                11.63   \n",
              "2                                48.41                                32.27   \n",
              "3                                89.59                                64.73   \n",
              "4                                77.62                                53.68   \n",
              "\n",
              "   POTASH CONSUMPTION (tons)  POTASH SHARE IN NPK (Percent)  \\\n",
              "0                     1383.0                            NaN   \n",
              "1                     1363.0                           4.03   \n",
              "2                     7882.0                           6.86   \n",
              "3                    18271.0                          14.01   \n",
              "4                        NaN                          13.34   \n",
              "\n",
              "   POTASH PER HA OF NCA (Kg per ha)  POTASH PER HA OF GCA (Kg per ha)  \\\n",
              "0                              5.79                              4.21   \n",
              "1                              5.67                              3.11   \n",
              "2                             19.71                             13.31   \n",
              "3                             42.18                             33.22   \n",
              "4                             29.04                             21.79   \n",
              "\n",
              "   TOTAL CONSUMPTION (tons)  TOTAL PER HA OF NCA (Kg per ha)  \\\n",
              "0                   41684.0                            85.21   \n",
              "1                   44809.0                            90.08   \n",
              "2                       NaN                           303.24   \n",
              "3                  165898.0                           375.97   \n",
              "4                  139778.0                              NaN   \n",
              "\n",
              "   TOTAL PER HA OF GCA (Kg per ha)  \n",
              "0                            67.77  \n",
              "1                            73.74  \n",
              "2                           194.95  \n",
              "3                           266.35  \n",
              "4                           193.57  \n",
              "\n",
              "[5 rows x 101 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b06eafc2-725c-478a-bc02-b1a9ba248830\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>COTTON AREA (1000 ha)</th>\n",
              "      <th>COTTON PRODUCTION (1000 tons)</th>\n",
              "      <th>COTTON YIELD (Kg per ha)</th>\n",
              "      <th>JANUARY PERCIPITATION (Millimeters)</th>\n",
              "      <th>FEBRUARY PERCIPITATION (Millimeters)</th>\n",
              "      <th>MARCH PERCIPITATION (Millimeters)</th>\n",
              "      <th>APRIL PERCIPITATION (Millimeters)</th>\n",
              "      <th>MAY PERCIPITATION (Millimeters)</th>\n",
              "      <th>JUNE PERCIPITATION (Millimeters)</th>\n",
              "      <th>...</th>\n",
              "      <th>PHOSPHATE SHARE IN NPK (Percent)</th>\n",
              "      <th>PHOSPHATE PER HA OF NCA (Kg per ha)</th>\n",
              "      <th>PHOSPHATE PER HA OF GCA (Kg per ha)</th>\n",
              "      <th>POTASH CONSUMPTION (tons)</th>\n",
              "      <th>POTASH SHARE IN NPK (Percent)</th>\n",
              "      <th>POTASH PER HA OF NCA (Kg per ha)</th>\n",
              "      <th>POTASH PER HA OF GCA (Kg per ha)</th>\n",
              "      <th>TOTAL CONSUMPTION (tons)</th>\n",
              "      <th>TOTAL PER HA OF NCA (Kg per ha)</th>\n",
              "      <th>TOTAL PER HA OF GCA (Kg per ha)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1990</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.05</td>\n",
              "      <td>50.75</td>\n",
              "      <td>75.34</td>\n",
              "      <td>18.87</td>\n",
              "      <td>57.59</td>\n",
              "      <td>123.74</td>\n",
              "      <td>...</td>\n",
              "      <td>23.32</td>\n",
              "      <td>19.79</td>\n",
              "      <td>15.90</td>\n",
              "      <td>1383.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.79</td>\n",
              "      <td>4.21</td>\n",
              "      <td>41684.0</td>\n",
              "      <td>85.21</td>\n",
              "      <td>67.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1990</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3333</td>\n",
              "      <td>NaN</td>\n",
              "      <td>54.03</td>\n",
              "      <td>94.67</td>\n",
              "      <td>12.21</td>\n",
              "      <td>143.97</td>\n",
              "      <td>115.08</td>\n",
              "      <td>...</td>\n",
              "      <td>18.24</td>\n",
              "      <td>15.43</td>\n",
              "      <td>11.63</td>\n",
              "      <td>1363.0</td>\n",
              "      <td>4.03</td>\n",
              "      <td>5.67</td>\n",
              "      <td>3.11</td>\n",
              "      <td>44809.0</td>\n",
              "      <td>90.08</td>\n",
              "      <td>73.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1990</td>\n",
              "      <td>49.0</td>\n",
              "      <td>238.0</td>\n",
              "      <td>4944</td>\n",
              "      <td>3.28</td>\n",
              "      <td>39.90</td>\n",
              "      <td>68.64</td>\n",
              "      <td>8.12</td>\n",
              "      <td>207.71</td>\n",
              "      <td>131.98</td>\n",
              "      <td>...</td>\n",
              "      <td>19.69</td>\n",
              "      <td>48.41</td>\n",
              "      <td>32.27</td>\n",
              "      <td>7882.0</td>\n",
              "      <td>6.86</td>\n",
              "      <td>19.71</td>\n",
              "      <td>13.31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>303.24</td>\n",
              "      <td>194.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1990</td>\n",
              "      <td>26.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>4964</td>\n",
              "      <td>4.14</td>\n",
              "      <td>43.94</td>\n",
              "      <td>48.83</td>\n",
              "      <td>5.39</td>\n",
              "      <td>230.23</td>\n",
              "      <td>146.55</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>89.59</td>\n",
              "      <td>64.73</td>\n",
              "      <td>18271.0</td>\n",
              "      <td>14.01</td>\n",
              "      <td>42.18</td>\n",
              "      <td>33.22</td>\n",
              "      <td>165898.0</td>\n",
              "      <td>375.97</td>\n",
              "      <td>266.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1990</td>\n",
              "      <td>996.0</td>\n",
              "      <td>289.0</td>\n",
              "      <td>2892</td>\n",
              "      <td>1.18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32.47</td>\n",
              "      <td>2.26</td>\n",
              "      <td>236.77</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>28.12</td>\n",
              "      <td>77.62</td>\n",
              "      <td>53.68</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.34</td>\n",
              "      <td>29.04</td>\n",
              "      <td>21.79</td>\n",
              "      <td>139778.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>193.57</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 101 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b06eafc2-725c-478a-bc02-b1a9ba248830')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b06eafc2-725c-478a-bc02-b1a9ba248830 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b06eafc2-725c-478a-bc02-b1a9ba248830');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df = india_train.select_dtypes(['float', 'int'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a6395964",
      "metadata": {
        "id": "a6395964"
      },
      "outputs": [],
      "source": [
        "for i in df.columns:\n",
        "    df[i] = df[i].fillna(df[i].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "26e65163",
      "metadata": {
        "id": "26e65163"
      },
      "outputs": [],
      "source": [
        "x, y = df.drop('COTTON YIELD (Kg per ha)', axis=1), df['COTTON YIELD (Kg per ha)']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1803933f",
      "metadata": {
        "id": "1803933f"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "a4dd0b82",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a4dd0b82",
        "outputId": "9497235f-c011-495b-a70e-332133fad080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lr:\n",
            "Score: 0.26267188359786997\n",
            "MSE: 20370511.943535946\n",
            "--------------------------------\n",
            "dt:\n",
            "Score: 0.31152981692880166\n",
            "MSE: 19020690.75495751\n",
            "--------------------------------\n",
            "ab:\n",
            "Score: 0.13770554491149123\n",
            "MSE: 23823015.97548918\n",
            "--------------------------------\n",
            "rf:\n",
            "Score: 0.5230624030686772\n",
            "MSE: 13176580.139135977\n",
            "--------------------------------\n",
            "svr:\n",
            "Score: -0.11974858511729014\n",
            "MSE: 30935822.76258812\n",
            "--------------------------------\n",
            "Epoch 1/1000\n",
            "103/103 [==============================] - 2s 11ms/step - loss: 28151546.0000 - accuracy: 0.0431\n",
            "Epoch 2/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 22229672.0000 - accuracy: 0.0055\n",
            "Epoch 3/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 21547460.0000 - accuracy: 0.0058\n",
            "Epoch 4/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 21123994.0000 - accuracy: 0.0091\n",
            "Epoch 5/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 20982428.0000 - accuracy: 0.0082\n",
            "Epoch 6/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 20402368.0000 - accuracy: 0.0064\n",
            "Epoch 7/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 20031322.0000 - accuracy: 0.0118\n",
            "Epoch 8/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 20349790.0000 - accuracy: 0.0097\n",
            "Epoch 9/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 19590340.0000 - accuracy: 0.0164\n",
            "Epoch 10/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 20310418.0000 - accuracy: 0.0079\n",
            "Epoch 11/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 18866592.0000 - accuracy: 0.0179\n",
            "Epoch 12/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 19411916.0000 - accuracy: 0.0191\n",
            "Epoch 13/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 18444522.0000 - accuracy: 0.0100\n",
            "Epoch 14/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 18705612.0000 - accuracy: 0.0167\n",
            "Epoch 15/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 18661490.0000 - accuracy: 0.0401\n",
            "Epoch 16/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 19714496.0000 - accuracy: 0.0358\n",
            "Epoch 17/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 17955550.0000 - accuracy: 0.0118\n",
            "Epoch 18/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 17188294.0000 - accuracy: 0.0143\n",
            "Epoch 19/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 19425962.0000 - accuracy: 0.0164\n",
            "Epoch 20/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 19382114.0000 - accuracy: 0.0255\n",
            "Epoch 21/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 17942940.0000 - accuracy: 0.0073\n",
            "Epoch 22/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 18706188.0000 - accuracy: 0.0109\n",
            "Epoch 23/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 18099482.0000 - accuracy: 0.0152\n",
            "Epoch 24/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 16610852.0000 - accuracy: 0.0115\n",
            "Epoch 25/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 15713421.0000 - accuracy: 0.0173\n",
            "Epoch 26/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 17114218.0000 - accuracy: 0.0146\n",
            "Epoch 27/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 13140708.0000 - accuracy: 0.0155\n",
            "Epoch 28/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 15232280.0000 - accuracy: 0.0140\n",
            "Epoch 29/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 16062793.0000 - accuracy: 0.0194\n",
            "Epoch 30/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 14201163.0000 - accuracy: 0.0039\n",
            "Epoch 31/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 12906804.0000 - accuracy: 0.0052\n",
            "Epoch 32/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 12222698.0000 - accuracy: 0.0018\n",
            "Epoch 33/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 13871842.0000 - accuracy: 0.0012\n",
            "Epoch 34/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 13483362.0000 - accuracy: 0.0015\n",
            "Epoch 35/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 15353052.0000 - accuracy: 0.0021\n",
            "Epoch 36/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 16298727.0000 - accuracy: 6.0735e-04\n",
            "Epoch 37/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 15692688.0000 - accuracy: 0.0058\n",
            "Epoch 38/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 17175034.0000 - accuracy: 0.0131\n",
            "Epoch 39/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 17909420.0000 - accuracy: 0.0234\n",
            "Epoch 40/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 15279670.0000 - accuracy: 0.0237\n",
            "Epoch 41/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 13351638.0000 - accuracy: 0.0030\n",
            "Epoch 42/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 11017327.0000 - accuracy: 3.0367e-04\n",
            "Epoch 43/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 12902090.0000 - accuracy: 0.0015\n",
            "Epoch 44/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 14259532.0000 - accuracy: 0.0055\n",
            "Epoch 45/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 11726231.0000 - accuracy: 6.0735e-04\n",
            "Epoch 46/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 12378017.0000 - accuracy: 0.0021\n",
            "Epoch 47/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 12137317.0000 - accuracy: 0.0030\n",
            "Epoch 48/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 13288945.0000 - accuracy: 0.0021\n",
            "Epoch 49/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 11804305.0000 - accuracy: 9.1102e-04\n",
            "Epoch 50/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 11131515.0000 - accuracy: 6.0735e-04\n",
            "Epoch 51/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 9804436.0000 - accuracy: 0.0000e+00\n",
            "Epoch 52/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 10811062.0000 - accuracy: 6.0735e-04\n",
            "Epoch 53/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 11318881.0000 - accuracy: 6.0735e-04\n",
            "Epoch 54/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 10956302.0000 - accuracy: 0.0012\n",
            "Epoch 55/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 10239560.0000 - accuracy: 9.1102e-04\n",
            "Epoch 56/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 10840766.0000 - accuracy: 3.0367e-04\n",
            "Epoch 57/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 10555901.0000 - accuracy: 3.0367e-04\n",
            "Epoch 58/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 10433615.0000 - accuracy: 3.0367e-04\n",
            "Epoch 59/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 10716222.0000 - accuracy: 0.0061\n",
            "Epoch 60/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 10790771.0000 - accuracy: 0.0000e+00\n",
            "Epoch 61/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 8872743.0000 - accuracy: 0.0012\n",
            "Epoch 62/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 10999030.0000 - accuracy: 0.0012\n",
            "Epoch 63/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 9759044.0000 - accuracy: 3.0367e-04\n",
            "Epoch 64/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 9835805.0000 - accuracy: 0.0000e+00\n",
            "Epoch 65/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 10807295.0000 - accuracy: 6.0735e-04\n",
            "Epoch 66/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 9466279.0000 - accuracy: 6.0735e-04\n",
            "Epoch 67/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 9757624.0000 - accuracy: 0.0000e+00\n",
            "Epoch 68/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 8000984.5000 - accuracy: 3.0367e-04\n",
            "Epoch 69/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 9638721.0000 - accuracy: 0.0030\n",
            "Epoch 70/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 12486323.0000 - accuracy: 0.0021\n",
            "Epoch 71/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 10489656.0000 - accuracy: 6.0735e-04\n",
            "Epoch 72/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 9107356.0000 - accuracy: 3.0367e-04\n",
            "Epoch 73/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 8258278.5000 - accuracy: 0.0012\n",
            "Epoch 74/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 11885082.0000 - accuracy: 0.0000e+00\n",
            "Epoch 75/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 10183010.0000 - accuracy: 0.0000e+00\n",
            "Epoch 76/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 8832556.0000 - accuracy: 6.0735e-04\n",
            "Epoch 77/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 9076564.0000 - accuracy: 9.1102e-04\n",
            "Epoch 78/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 8735325.0000 - accuracy: 9.1102e-04\n",
            "Epoch 79/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 8673366.0000 - accuracy: 0.0000e+00\n",
            "Epoch 80/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 12850841.0000 - accuracy: 9.1102e-04\n",
            "Epoch 81/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 11057481.0000 - accuracy: 3.0367e-04\n",
            "Epoch 82/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 7845414.0000 - accuracy: 3.0367e-04\n",
            "Epoch 83/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 10912882.0000 - accuracy: 0.0000e+00\n",
            "Epoch 84/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 9729297.0000 - accuracy: 6.0735e-04\n",
            "Epoch 85/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 9046205.0000 - accuracy: 9.1102e-04\n",
            "Epoch 86/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 8655967.0000 - accuracy: 0.0027\n",
            "Epoch 87/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 8142768.5000 - accuracy: 0.0018\n",
            "Epoch 88/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 8793827.0000 - accuracy: 0.0000e+00\n",
            "Epoch 89/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 9472614.0000 - accuracy: 6.0735e-04\n",
            "Epoch 90/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 7057877.0000 - accuracy: 6.0735e-04\n",
            "Epoch 91/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 10037111.0000 - accuracy: 0.0000e+00\n",
            "Epoch 92/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 7735375.5000 - accuracy: 9.1102e-04\n",
            "Epoch 93/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 6717529.0000 - accuracy: 0.0024\n",
            "Epoch 94/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 9652554.0000 - accuracy: 9.1102e-04\n",
            "Epoch 95/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 7297184.0000 - accuracy: 0.0012\n",
            "Epoch 96/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 8755988.0000 - accuracy: 3.0367e-04\n",
            "Epoch 97/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 10052400.0000 - accuracy: 0.0018\n",
            "Epoch 98/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 7062895.0000 - accuracy: 0.0015\n",
            "Epoch 99/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6992656.0000 - accuracy: 6.0735e-04\n",
            "Epoch 100/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 7168290.0000 - accuracy: 9.1102e-04\n",
            "Epoch 101/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 7496297.5000 - accuracy: 9.1102e-04\n",
            "Epoch 102/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 9283142.0000 - accuracy: 0.0000e+00\n",
            "Epoch 103/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 7416212.5000 - accuracy: 3.0367e-04\n",
            "Epoch 104/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 8147094.0000 - accuracy: 3.0367e-04\n",
            "Epoch 105/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 7936557.0000 - accuracy: 0.0000e+00\n",
            "Epoch 106/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6698600.0000 - accuracy: 6.0735e-04\n",
            "Epoch 107/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 7714239.0000 - accuracy: 0.0000e+00\n",
            "Epoch 108/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 8089626.5000 - accuracy: 6.0735e-04\n",
            "Epoch 109/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 6720492.5000 - accuracy: 6.0735e-04\n",
            "Epoch 110/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 6590836.0000 - accuracy: 0.0000e+00\n",
            "Epoch 111/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6628700.5000 - accuracy: 3.0367e-04\n",
            "Epoch 112/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 7562689.5000 - accuracy: 0.0027\n",
            "Epoch 113/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 8762190.0000 - accuracy: 0.0000e+00\n",
            "Epoch 114/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 7465597.0000 - accuracy: 3.0367e-04\n",
            "Epoch 115/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 7939188.5000 - accuracy: 0.0000e+00\n",
            "Epoch 116/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 9069731.0000 - accuracy: 6.0735e-04\n",
            "Epoch 117/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 7350927.5000 - accuracy: 3.0367e-04\n",
            "Epoch 118/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 7047025.0000 - accuracy: 3.0367e-04\n",
            "Epoch 119/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6661865.5000 - accuracy: 0.0000e+00\n",
            "Epoch 120/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6958494.5000 - accuracy: 0.0000e+00\n",
            "Epoch 121/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 7850719.5000 - accuracy: 0.0000e+00\n",
            "Epoch 122/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6809610.5000 - accuracy: 0.0000e+00\n",
            "Epoch 123/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 7067730.0000 - accuracy: 0.0000e+00\n",
            "Epoch 124/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 7231169.0000 - accuracy: 0.0000e+00\n",
            "Epoch 125/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 7010449.5000 - accuracy: 0.0015\n",
            "Epoch 126/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 8421336.0000 - accuracy: 0.0000e+00\n",
            "Epoch 127/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 7133464.5000 - accuracy: 3.0367e-04\n",
            "Epoch 128/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 7635091.0000 - accuracy: 3.0367e-04\n",
            "Epoch 129/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 6987221.0000 - accuracy: 6.0735e-04\n",
            "Epoch 130/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 7875873.5000 - accuracy: 0.0036\n",
            "Epoch 131/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6691547.0000 - accuracy: 0.0000e+00\n",
            "Epoch 132/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 7221142.5000 - accuracy: 3.0367e-04\n",
            "Epoch 133/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 7936346.0000 - accuracy: 3.0367e-04\n",
            "Epoch 134/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 7461684.5000 - accuracy: 0.0024\n",
            "Epoch 135/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6963261.0000 - accuracy: 3.0367e-04\n",
            "Epoch 136/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 7705214.5000 - accuracy: 0.0000e+00\n",
            "Epoch 137/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 8376952.0000 - accuracy: 3.0367e-04\n",
            "Epoch 138/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 6112570.0000 - accuracy: 6.0735e-04\n",
            "Epoch 139/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 6468549.0000 - accuracy: 0.0000e+00\n",
            "Epoch 140/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 6819457.5000 - accuracy: 0.0000e+00\n",
            "Epoch 141/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6024101.0000 - accuracy: 6.0735e-04\n",
            "Epoch 142/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6459960.5000 - accuracy: 6.0735e-04\n",
            "Epoch 143/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 7151003.0000 - accuracy: 3.0367e-04\n",
            "Epoch 144/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 6385717.5000 - accuracy: 0.0000e+00\n",
            "Epoch 145/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6071494.5000 - accuracy: 0.0000e+00\n",
            "Epoch 146/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 7617058.0000 - accuracy: 3.0367e-04\n",
            "Epoch 147/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6793062.0000 - accuracy: 0.0000e+00\n",
            "Epoch 148/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 7134667.5000 - accuracy: 0.0021\n",
            "Epoch 149/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 7034138.5000 - accuracy: 0.0000e+00\n",
            "Epoch 150/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 7639327.5000 - accuracy: 0.0000e+00\n",
            "Epoch 151/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6224338.0000 - accuracy: 0.0000e+00\n",
            "Epoch 152/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6678202.5000 - accuracy: 0.0000e+00\n",
            "Epoch 153/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 6579379.5000 - accuracy: 9.1102e-04\n",
            "Epoch 154/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 7097929.0000 - accuracy: 9.1102e-04\n",
            "Epoch 155/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 8399270.0000 - accuracy: 6.0735e-04\n",
            "Epoch 156/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6509497.0000 - accuracy: 0.0000e+00\n",
            "Epoch 157/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 7442682.0000 - accuracy: 0.0000e+00\n",
            "Epoch 158/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6735390.0000 - accuracy: 0.0000e+00\n",
            "Epoch 159/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 6468903.0000 - accuracy: 0.0000e+00\n",
            "Epoch 160/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6410994.5000 - accuracy: 0.0000e+00\n",
            "Epoch 161/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 7017075.5000 - accuracy: 0.0000e+00\n",
            "Epoch 162/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 6335783.5000 - accuracy: 0.0000e+00\n",
            "Epoch 163/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 6080496.5000 - accuracy: 0.0000e+00\n",
            "Epoch 164/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 4462673.5000 - accuracy: 0.0000e+00\n",
            "Epoch 165/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6916840.5000 - accuracy: 6.0735e-04\n",
            "Epoch 166/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 8417164.0000 - accuracy: 6.0735e-04\n",
            "Epoch 167/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5886824.5000 - accuracy: 3.0367e-04\n",
            "Epoch 168/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6018675.0000 - accuracy: 0.0000e+00\n",
            "Epoch 169/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 7535403.5000 - accuracy: 0.0000e+00\n",
            "Epoch 170/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 5711434.0000 - accuracy: 0.0000e+00\n",
            "Epoch 171/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 6610351.5000 - accuracy: 0.0000e+00\n",
            "Epoch 172/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6837236.0000 - accuracy: 0.0000e+00\n",
            "Epoch 173/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5877063.0000 - accuracy: 0.0000e+00\n",
            "Epoch 174/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 7042952.0000 - accuracy: 0.0000e+00\n",
            "Epoch 175/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6871249.0000 - accuracy: 0.0000e+00\n",
            "Epoch 176/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 6150366.0000 - accuracy: 0.0000e+00\n",
            "Epoch 177/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5946840.5000 - accuracy: 3.0367e-04\n",
            "Epoch 178/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6884996.0000 - accuracy: 0.0000e+00\n",
            "Epoch 179/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 5739133.0000 - accuracy: 0.0000e+00\n",
            "Epoch 180/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 5603452.0000 - accuracy: 3.0367e-04\n",
            "Epoch 181/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5685659.0000 - accuracy: 0.0000e+00\n",
            "Epoch 182/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 6057310.5000 - accuracy: 3.0367e-04\n",
            "Epoch 183/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 7392733.5000 - accuracy: 3.0367e-04\n",
            "Epoch 184/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 5243364.0000 - accuracy: 6.0735e-04\n",
            "Epoch 185/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 6767463.5000 - accuracy: 0.0000e+00\n",
            "Epoch 186/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 8663661.0000 - accuracy: 0.0000e+00\n",
            "Epoch 187/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 6760938.5000 - accuracy: 0.0000e+00\n",
            "Epoch 188/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6335402.0000 - accuracy: 3.0367e-04\n",
            "Epoch 189/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 6609972.5000 - accuracy: 0.0000e+00\n",
            "Epoch 190/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5439605.5000 - accuracy: 0.0000e+00\n",
            "Epoch 191/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5681965.0000 - accuracy: 0.0000e+00\n",
            "Epoch 192/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5748542.0000 - accuracy: 0.0000e+00\n",
            "Epoch 193/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6511668.5000 - accuracy: 0.0000e+00\n",
            "Epoch 194/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6338706.0000 - accuracy: 0.0000e+00\n",
            "Epoch 195/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5797333.0000 - accuracy: 0.0000e+00\n",
            "Epoch 196/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5841633.0000 - accuracy: 0.0000e+00\n",
            "Epoch 197/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6682593.5000 - accuracy: 0.0000e+00\n",
            "Epoch 198/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6132779.0000 - accuracy: 0.0000e+00\n",
            "Epoch 199/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 5568871.5000 - accuracy: 0.0000e+00\n",
            "Epoch 200/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 5368525.5000 - accuracy: 0.0000e+00\n",
            "Epoch 201/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 5688332.0000 - accuracy: 0.0000e+00\n",
            "Epoch 202/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5537279.0000 - accuracy: 0.0000e+00\n",
            "Epoch 203/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 5134947.5000 - accuracy: 0.0000e+00\n",
            "Epoch 204/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5999619.0000 - accuracy: 3.0367e-04\n",
            "Epoch 205/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5645315.5000 - accuracy: 0.0000e+00\n",
            "Epoch 206/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6046456.5000 - accuracy: 0.0000e+00\n",
            "Epoch 207/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5773067.5000 - accuracy: 0.0000e+00\n",
            "Epoch 208/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6160744.0000 - accuracy: 3.0367e-04\n",
            "Epoch 209/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 5575388.0000 - accuracy: 0.0000e+00\n",
            "Epoch 210/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6614662.0000 - accuracy: 0.0000e+00\n",
            "Epoch 211/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5528391.0000 - accuracy: 0.0000e+00\n",
            "Epoch 212/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 5290599.0000 - accuracy: 0.0000e+00\n",
            "Epoch 213/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 5720778.5000 - accuracy: 0.0000e+00\n",
            "Epoch 214/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 7744440.0000 - accuracy: 0.0000e+00\n",
            "Epoch 215/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 5776645.0000 - accuracy: 3.0367e-04\n",
            "Epoch 216/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 5350793.5000 - accuracy: 0.0000e+00\n",
            "Epoch 217/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 5064348.5000 - accuracy: 0.0000e+00\n",
            "Epoch 218/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6173485.0000 - accuracy: 0.0000e+00\n",
            "Epoch 219/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 5518577.5000 - accuracy: 0.0000e+00\n",
            "Epoch 220/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 6372891.0000 - accuracy: 0.0000e+00\n",
            "Epoch 221/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5193818.0000 - accuracy: 0.0000e+00\n",
            "Epoch 222/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 5904059.5000 - accuracy: 0.0000e+00\n",
            "Epoch 223/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 9030808.0000 - accuracy: 0.0000e+00\n",
            "Epoch 224/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 7138767.5000 - accuracy: 0.0000e+00\n",
            "Epoch 225/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5972427.5000 - accuracy: 0.0000e+00\n",
            "Epoch 226/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 5510472.0000 - accuracy: 0.0000e+00\n",
            "Epoch 227/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5596428.5000 - accuracy: 0.0000e+00\n",
            "Epoch 228/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4805398.0000 - accuracy: 0.0000e+00\n",
            "Epoch 229/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5205560.0000 - accuracy: 0.0000e+00\n",
            "Epoch 230/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 5701142.0000 - accuracy: 0.0000e+00\n",
            "Epoch 231/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 6823020.5000 - accuracy: 0.0000e+00\n",
            "Epoch 232/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 5436048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 233/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 6375497.0000 - accuracy: 0.0000e+00\n",
            "Epoch 234/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 5246351.0000 - accuracy: 0.0000e+00\n",
            "Epoch 235/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4834345.0000 - accuracy: 0.0000e+00\n",
            "Epoch 236/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4928436.0000 - accuracy: 0.0000e+00\n",
            "Epoch 237/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5419615.0000 - accuracy: 0.0000e+00\n",
            "Epoch 238/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6219578.0000 - accuracy: 0.0000e+00\n",
            "Epoch 239/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5747224.0000 - accuracy: 0.0000e+00\n",
            "Epoch 240/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5759056.0000 - accuracy: 0.0000e+00\n",
            "Epoch 241/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6519064.5000 - accuracy: 0.0000e+00\n",
            "Epoch 242/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 6459745.5000 - accuracy: 0.0000e+00\n",
            "Epoch 243/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4737585.5000 - accuracy: 0.0000e+00\n",
            "Epoch 244/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6318789.5000 - accuracy: 0.0000e+00\n",
            "Epoch 245/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 7720041.0000 - accuracy: 3.0367e-04\n",
            "Epoch 246/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 5231649.5000 - accuracy: 3.0367e-04\n",
            "Epoch 247/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 5801431.0000 - accuracy: 0.0000e+00\n",
            "Epoch 248/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 6531508.5000 - accuracy: 0.0000e+00\n",
            "Epoch 249/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 5072785.5000 - accuracy: 0.0000e+00\n",
            "Epoch 250/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5269919.0000 - accuracy: 3.0367e-04\n",
            "Epoch 251/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6215680.0000 - accuracy: 0.0000e+00\n",
            "Epoch 252/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5640009.0000 - accuracy: 0.0000e+00\n",
            "Epoch 253/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 5057781.5000 - accuracy: 0.0000e+00\n",
            "Epoch 254/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4829075.5000 - accuracy: 0.0000e+00\n",
            "Epoch 255/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5276461.0000 - accuracy: 0.0000e+00\n",
            "Epoch 256/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5928199.5000 - accuracy: 0.0000e+00\n",
            "Epoch 257/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6239875.0000 - accuracy: 0.0000e+00\n",
            "Epoch 258/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4857579.5000 - accuracy: 0.0000e+00\n",
            "Epoch 259/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5071078.0000 - accuracy: 0.0000e+00\n",
            "Epoch 260/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 5265837.0000 - accuracy: 0.0000e+00\n",
            "Epoch 261/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 12978928.0000 - accuracy: 0.0000e+00\n",
            "Epoch 262/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 8498081.0000 - accuracy: 0.0000e+00\n",
            "Epoch 263/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6815072.5000 - accuracy: 0.0000e+00\n",
            "Epoch 264/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 5782417.5000 - accuracy: 0.0000e+00\n",
            "Epoch 265/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6006794.5000 - accuracy: 0.0000e+00\n",
            "Epoch 266/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 5882565.5000 - accuracy: 0.0000e+00\n",
            "Epoch 267/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5607324.5000 - accuracy: 0.0000e+00\n",
            "Epoch 268/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6741276.5000 - accuracy: 0.0000e+00\n",
            "Epoch 269/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5837693.5000 - accuracy: 0.0000e+00\n",
            "Epoch 270/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5723026.0000 - accuracy: 0.0000e+00\n",
            "Epoch 271/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5252699.0000 - accuracy: 0.0000e+00\n",
            "Epoch 272/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5125108.5000 - accuracy: 0.0000e+00\n",
            "Epoch 273/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5056833.0000 - accuracy: 0.0000e+00\n",
            "Epoch 274/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4601037.0000 - accuracy: 0.0000e+00\n",
            "Epoch 275/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 4670039.0000 - accuracy: 0.0000e+00\n",
            "Epoch 276/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 5021416.0000 - accuracy: 0.0000e+00\n",
            "Epoch 277/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 4956310.0000 - accuracy: 0.0000e+00\n",
            "Epoch 278/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 4877730.5000 - accuracy: 3.0367e-04\n",
            "Epoch 279/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6035724.5000 - accuracy: 0.0000e+00\n",
            "Epoch 280/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5332082.0000 - accuracy: 0.0000e+00\n",
            "Epoch 281/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 5128042.0000 - accuracy: 0.0000e+00\n",
            "Epoch 282/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5640918.0000 - accuracy: 0.0000e+00\n",
            "Epoch 283/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4379746.5000 - accuracy: 0.0000e+00\n",
            "Epoch 284/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5566828.5000 - accuracy: 0.0000e+00\n",
            "Epoch 285/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4685536.5000 - accuracy: 0.0000e+00\n",
            "Epoch 286/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5014548.0000 - accuracy: 0.0000e+00\n",
            "Epoch 287/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6028560.5000 - accuracy: 0.0000e+00\n",
            "Epoch 288/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4928094.5000 - accuracy: 0.0000e+00\n",
            "Epoch 289/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5579476.5000 - accuracy: 3.0367e-04\n",
            "Epoch 290/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 5846239.5000 - accuracy: 0.0000e+00\n",
            "Epoch 291/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 5060280.5000 - accuracy: 0.0000e+00\n",
            "Epoch 292/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 5201414.0000 - accuracy: 0.0000e+00\n",
            "Epoch 293/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 5602487.0000 - accuracy: 0.0000e+00\n",
            "Epoch 294/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5753100.5000 - accuracy: 0.0000e+00\n",
            "Epoch 295/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5680564.5000 - accuracy: 0.0000e+00\n",
            "Epoch 296/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5132923.5000 - accuracy: 0.0000e+00\n",
            "Epoch 297/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4495177.0000 - accuracy: 0.0000e+00\n",
            "Epoch 298/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5898156.0000 - accuracy: 0.0000e+00\n",
            "Epoch 299/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5256109.5000 - accuracy: 0.0000e+00\n",
            "Epoch 300/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4918314.0000 - accuracy: 0.0000e+00\n",
            "Epoch 301/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5089671.5000 - accuracy: 0.0000e+00\n",
            "Epoch 302/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5462171.0000 - accuracy: 0.0000e+00\n",
            "Epoch 303/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4204425.0000 - accuracy: 0.0000e+00\n",
            "Epoch 304/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5586614.5000 - accuracy: 0.0000e+00\n",
            "Epoch 305/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 5217237.5000 - accuracy: 0.0000e+00\n",
            "Epoch 306/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 5032832.0000 - accuracy: 0.0000e+00\n",
            "Epoch 307/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 4265000.5000 - accuracy: 0.0000e+00\n",
            "Epoch 308/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 4997726.0000 - accuracy: 0.0000e+00\n",
            "Epoch 309/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 5535074.0000 - accuracy: 0.0000e+00\n",
            "Epoch 310/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 6004586.0000 - accuracy: 0.0000e+00\n",
            "Epoch 311/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5394654.5000 - accuracy: 0.0000e+00\n",
            "Epoch 312/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5532295.0000 - accuracy: 0.0000e+00\n",
            "Epoch 313/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4771222.5000 - accuracy: 0.0000e+00\n",
            "Epoch 314/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4467714.5000 - accuracy: 0.0000e+00\n",
            "Epoch 315/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4771609.5000 - accuracy: 0.0000e+00\n",
            "Epoch 316/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4548044.0000 - accuracy: 0.0000e+00\n",
            "Epoch 317/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5263624.5000 - accuracy: 0.0000e+00\n",
            "Epoch 318/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4530570.0000 - accuracy: 0.0000e+00\n",
            "Epoch 319/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 9356149.0000 - accuracy: 0.0000e+00\n",
            "Epoch 320/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 5791142.0000 - accuracy: 0.0000e+00\n",
            "Epoch 321/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 4684294.5000 - accuracy: 0.0000e+00\n",
            "Epoch 322/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 4747574.0000 - accuracy: 0.0000e+00\n",
            "Epoch 323/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 5087859.0000 - accuracy: 0.0000e+00\n",
            "Epoch 324/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 4582445.0000 - accuracy: 0.0000e+00\n",
            "Epoch 325/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4525599.5000 - accuracy: 0.0000e+00\n",
            "Epoch 326/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4447109.0000 - accuracy: 0.0000e+00\n",
            "Epoch 327/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4193752.7500 - accuracy: 0.0000e+00\n",
            "Epoch 328/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4010049.0000 - accuracy: 0.0000e+00\n",
            "Epoch 329/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4671922.5000 - accuracy: 0.0000e+00\n",
            "Epoch 330/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4495089.0000 - accuracy: 0.0000e+00\n",
            "Epoch 331/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4440951.0000 - accuracy: 0.0000e+00\n",
            "Epoch 332/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4698141.0000 - accuracy: 0.0000e+00\n",
            "Epoch 333/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5399748.0000 - accuracy: 0.0000e+00\n",
            "Epoch 334/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6091291.0000 - accuracy: 0.0000e+00\n",
            "Epoch 335/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3921793.5000 - accuracy: 3.0367e-04\n",
            "Epoch 336/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 5195446.0000 - accuracy: 0.0000e+00\n",
            "Epoch 337/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 6012214.5000 - accuracy: 0.0000e+00\n",
            "Epoch 338/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5698423.5000 - accuracy: 0.0000e+00\n",
            "Epoch 339/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4729419.0000 - accuracy: 0.0000e+00\n",
            "Epoch 340/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4401148.5000 - accuracy: 0.0000e+00\n",
            "Epoch 341/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4374632.0000 - accuracy: 0.0000e+00\n",
            "Epoch 342/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4294250.0000 - accuracy: 0.0000e+00\n",
            "Epoch 343/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5436879.5000 - accuracy: 0.0000e+00\n",
            "Epoch 344/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3684211.2500 - accuracy: 0.0000e+00\n",
            "Epoch 345/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4593820.5000 - accuracy: 0.0000e+00\n",
            "Epoch 346/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4816890.0000 - accuracy: 0.0000e+00\n",
            "Epoch 347/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5028009.0000 - accuracy: 3.0367e-04\n",
            "Epoch 348/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5499004.5000 - accuracy: 0.0000e+00\n",
            "Epoch 349/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5393549.5000 - accuracy: 0.0000e+00\n",
            "Epoch 350/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 4897748.0000 - accuracy: 0.0000e+00\n",
            "Epoch 351/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 5063285.5000 - accuracy: 0.0000e+00\n",
            "Epoch 352/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 4190167.2500 - accuracy: 0.0000e+00\n",
            "Epoch 353/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6467847.0000 - accuracy: 0.0000e+00\n",
            "Epoch 354/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 4070548.7500 - accuracy: 0.0000e+00\n",
            "Epoch 355/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4218560.0000 - accuracy: 0.0000e+00\n",
            "Epoch 356/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4088076.2500 - accuracy: 0.0000e+00\n",
            "Epoch 357/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4970555.5000 - accuracy: 0.0000e+00\n",
            "Epoch 358/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4193633.5000 - accuracy: 0.0000e+00\n",
            "Epoch 359/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4490580.0000 - accuracy: 0.0000e+00\n",
            "Epoch 360/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4779763.5000 - accuracy: 0.0000e+00\n",
            "Epoch 361/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4274449.5000 - accuracy: 0.0000e+00\n",
            "Epoch 362/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4362936.5000 - accuracy: 0.0000e+00\n",
            "Epoch 363/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4538852.5000 - accuracy: 0.0000e+00\n",
            "Epoch 364/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4544567.5000 - accuracy: 0.0000e+00\n",
            "Epoch 365/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 3948205.7500 - accuracy: 3.0367e-04\n",
            "Epoch 366/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 4948557.0000 - accuracy: 0.0000e+00\n",
            "Epoch 367/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 6078317.0000 - accuracy: 6.0735e-04\n",
            "Epoch 368/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4705471.0000 - accuracy: 3.0367e-04\n",
            "Epoch 369/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5463171.0000 - accuracy: 0.0000e+00\n",
            "Epoch 370/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4832452.0000 - accuracy: 0.0000e+00\n",
            "Epoch 371/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4821615.0000 - accuracy: 0.0000e+00\n",
            "Epoch 372/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4780942.5000 - accuracy: 0.0000e+00\n",
            "Epoch 373/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4985358.0000 - accuracy: 0.0000e+00\n",
            "Epoch 374/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3529210.5000 - accuracy: 0.0000e+00\n",
            "Epoch 375/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4648833.0000 - accuracy: 0.0000e+00\n",
            "Epoch 376/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5181603.0000 - accuracy: 0.0000e+00\n",
            "Epoch 377/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5481453.5000 - accuracy: 0.0000e+00\n",
            "Epoch 378/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4829279.0000 - accuracy: 0.0000e+00\n",
            "Epoch 379/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4266594.0000 - accuracy: 0.0000e+00\n",
            "Epoch 380/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 6837471.5000 - accuracy: 0.0000e+00\n",
            "Epoch 381/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 4594034.0000 - accuracy: 0.0000e+00\n",
            "Epoch 382/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 4909762.5000 - accuracy: 0.0000e+00\n",
            "Epoch 383/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5256164.5000 - accuracy: 0.0000e+00\n",
            "Epoch 384/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4904064.0000 - accuracy: 0.0000e+00\n",
            "Epoch 385/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4355583.5000 - accuracy: 0.0000e+00\n",
            "Epoch 386/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4232200.0000 - accuracy: 0.0000e+00\n",
            "Epoch 387/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4635003.0000 - accuracy: 0.0000e+00\n",
            "Epoch 388/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4179288.7500 - accuracy: 0.0000e+00\n",
            "Epoch 389/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4174519.2500 - accuracy: 0.0000e+00\n",
            "Epoch 390/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3997739.0000 - accuracy: 0.0000e+00\n",
            "Epoch 391/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4453845.5000 - accuracy: 3.0367e-04\n",
            "Epoch 392/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5219846.5000 - accuracy: 0.0000e+00\n",
            "Epoch 393/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4326397.0000 - accuracy: 0.0000e+00\n",
            "Epoch 394/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 7949412.0000 - accuracy: 0.0000e+00\n",
            "Epoch 395/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 6040105.0000 - accuracy: 0.0000e+00\n",
            "Epoch 396/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 4883349.5000 - accuracy: 0.0000e+00\n",
            "Epoch 397/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 4770411.5000 - accuracy: 0.0000e+00\n",
            "Epoch 398/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 4455038.5000 - accuracy: 0.0000e+00\n",
            "Epoch 399/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4056051.5000 - accuracy: 0.0000e+00\n",
            "Epoch 400/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4069289.7500 - accuracy: 0.0000e+00\n",
            "Epoch 401/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4496476.5000 - accuracy: 0.0000e+00\n",
            "Epoch 402/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4723629.5000 - accuracy: 0.0000e+00\n",
            "Epoch 403/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5304851.5000 - accuracy: 0.0000e+00\n",
            "Epoch 404/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3725288.7500 - accuracy: 0.0000e+00\n",
            "Epoch 405/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4371956.5000 - accuracy: 0.0000e+00\n",
            "Epoch 406/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3980516.0000 - accuracy: 0.0000e+00\n",
            "Epoch 407/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4205071.5000 - accuracy: 0.0000e+00\n",
            "Epoch 408/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4912006.5000 - accuracy: 0.0000e+00\n",
            "Epoch 409/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 4161628.0000 - accuracy: 0.0000e+00\n",
            "Epoch 410/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 4341544.0000 - accuracy: 0.0000e+00\n",
            "Epoch 411/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 4421924.5000 - accuracy: 0.0000e+00\n",
            "Epoch 412/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 5518528.0000 - accuracy: 0.0000e+00\n",
            "Epoch 413/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5587928.5000 - accuracy: 0.0000e+00\n",
            "Epoch 414/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4982116.0000 - accuracy: 0.0000e+00\n",
            "Epoch 415/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3706984.5000 - accuracy: 0.0000e+00\n",
            "Epoch 416/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4235314.5000 - accuracy: 0.0000e+00\n",
            "Epoch 417/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4412021.5000 - accuracy: 0.0000e+00\n",
            "Epoch 418/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4116540.2500 - accuracy: 0.0000e+00\n",
            "Epoch 419/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3635474.0000 - accuracy: 0.0000e+00\n",
            "Epoch 420/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4115368.0000 - accuracy: 0.0000e+00\n",
            "Epoch 421/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4731863.5000 - accuracy: 0.0000e+00\n",
            "Epoch 422/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4607928.5000 - accuracy: 0.0000e+00\n",
            "Epoch 423/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4080532.0000 - accuracy: 0.0000e+00\n",
            "Epoch 424/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3941072.7500 - accuracy: 0.0000e+00\n",
            "Epoch 425/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 4649791.0000 - accuracy: 0.0000e+00\n",
            "Epoch 426/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3762228.7500 - accuracy: 0.0000e+00\n",
            "Epoch 427/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 5356918.5000 - accuracy: 0.0000e+00\n",
            "Epoch 428/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4401009.5000 - accuracy: 0.0000e+00\n",
            "Epoch 429/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4357797.0000 - accuracy: 0.0000e+00\n",
            "Epoch 430/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4628561.0000 - accuracy: 0.0000e+00\n",
            "Epoch 431/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4500941.0000 - accuracy: 0.0000e+00\n",
            "Epoch 432/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3830331.5000 - accuracy: 0.0000e+00\n",
            "Epoch 433/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4753281.5000 - accuracy: 0.0000e+00\n",
            "Epoch 434/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3491235.2500 - accuracy: 0.0000e+00\n",
            "Epoch 435/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 4555806.5000 - accuracy: 0.0000e+00\n",
            "Epoch 436/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5407774.0000 - accuracy: 0.0000e+00\n",
            "Epoch 437/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4383578.5000 - accuracy: 0.0000e+00\n",
            "Epoch 438/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3829418.0000 - accuracy: 0.0000e+00\n",
            "Epoch 439/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 4304344.0000 - accuracy: 0.0000e+00\n",
            "Epoch 440/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 4373698.0000 - accuracy: 0.0000e+00\n",
            "Epoch 441/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 4196834.5000 - accuracy: 0.0000e+00\n",
            "Epoch 442/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 4458811.5000 - accuracy: 0.0000e+00\n",
            "Epoch 443/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3783611.2500 - accuracy: 0.0000e+00\n",
            "Epoch 444/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5121698.0000 - accuracy: 0.0000e+00\n",
            "Epoch 445/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4787005.5000 - accuracy: 0.0000e+00\n",
            "Epoch 446/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4105823.0000 - accuracy: 0.0000e+00\n",
            "Epoch 447/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3880575.0000 - accuracy: 0.0000e+00\n",
            "Epoch 448/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4113142.5000 - accuracy: 3.0367e-04\n",
            "Epoch 449/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4713599.0000 - accuracy: 0.0000e+00\n",
            "Epoch 450/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 6311902.0000 - accuracy: 0.0000e+00\n",
            "Epoch 451/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4433696.5000 - accuracy: 0.0000e+00\n",
            "Epoch 452/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3773624.7500 - accuracy: 0.0000e+00\n",
            "Epoch 453/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3697857.0000 - accuracy: 0.0000e+00\n",
            "Epoch 454/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 4142564.2500 - accuracy: 0.0000e+00\n",
            "Epoch 455/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 4329234.0000 - accuracy: 0.0000e+00\n",
            "Epoch 456/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 3771858.5000 - accuracy: 0.0000e+00\n",
            "Epoch 457/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 4358583.5000 - accuracy: 3.0367e-04\n",
            "Epoch 458/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4139324.2500 - accuracy: 0.0000e+00\n",
            "Epoch 459/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4175603.2500 - accuracy: 0.0000e+00\n",
            "Epoch 460/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3898722.2500 - accuracy: 0.0000e+00\n",
            "Epoch 461/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5058917.5000 - accuracy: 0.0000e+00\n",
            "Epoch 462/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3527911.7500 - accuracy: 0.0000e+00\n",
            "Epoch 463/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4093854.2500 - accuracy: 0.0000e+00\n",
            "Epoch 464/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3794092.5000 - accuracy: 0.0000e+00\n",
            "Epoch 465/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4202047.5000 - accuracy: 0.0000e+00\n",
            "Epoch 466/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3922499.2500 - accuracy: 0.0000e+00\n",
            "Epoch 467/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3715104.2500 - accuracy: 0.0000e+00\n",
            "Epoch 468/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3542341.2500 - accuracy: 0.0000e+00\n",
            "Epoch 469/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 3885035.2500 - accuracy: 0.0000e+00\n",
            "Epoch 470/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 4706797.0000 - accuracy: 0.0000e+00\n",
            "Epoch 471/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 5137338.0000 - accuracy: 0.0000e+00\n",
            "Epoch 472/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3729559.5000 - accuracy: 0.0000e+00\n",
            "Epoch 473/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3753233.2500 - accuracy: 0.0000e+00\n",
            "Epoch 474/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4187651.2500 - accuracy: 0.0000e+00\n",
            "Epoch 475/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4275859.5000 - accuracy: 0.0000e+00\n",
            "Epoch 476/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3461761.0000 - accuracy: 0.0000e+00\n",
            "Epoch 477/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4079722.7500 - accuracy: 0.0000e+00\n",
            "Epoch 478/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4274163.5000 - accuracy: 0.0000e+00\n",
            "Epoch 479/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3394838.2500 - accuracy: 0.0000e+00\n",
            "Epoch 480/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4180938.7500 - accuracy: 0.0000e+00\n",
            "Epoch 481/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4126815.2500 - accuracy: 0.0000e+00\n",
            "Epoch 482/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3845089.5000 - accuracy: 0.0000e+00\n",
            "Epoch 483/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4793240.5000 - accuracy: 0.0000e+00\n",
            "Epoch 484/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3658400.0000 - accuracy: 0.0000e+00\n",
            "Epoch 485/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 4784703.5000 - accuracy: 0.0000e+00\n",
            "Epoch 486/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 4251297.0000 - accuracy: 0.0000e+00\n",
            "Epoch 487/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 5225833.5000 - accuracy: 0.0000e+00\n",
            "Epoch 488/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3699730.2500 - accuracy: 0.0000e+00\n",
            "Epoch 489/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4124087.5000 - accuracy: 0.0000e+00\n",
            "Epoch 490/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3817057.2500 - accuracy: 0.0000e+00\n",
            "Epoch 491/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3579722.5000 - accuracy: 0.0000e+00\n",
            "Epoch 492/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4990060.0000 - accuracy: 0.0000e+00\n",
            "Epoch 493/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4710014.0000 - accuracy: 0.0000e+00\n",
            "Epoch 494/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4154988.2500 - accuracy: 0.0000e+00\n",
            "Epoch 495/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4370234.5000 - accuracy: 0.0000e+00\n",
            "Epoch 496/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4191026.2500 - accuracy: 0.0000e+00\n",
            "Epoch 497/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4703705.5000 - accuracy: 0.0000e+00\n",
            "Epoch 498/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4750029.0000 - accuracy: 0.0000e+00\n",
            "Epoch 499/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3186221.7500 - accuracy: 0.0000e+00\n",
            "Epoch 500/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3505430.2500 - accuracy: 0.0000e+00\n",
            "Epoch 501/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3250099.7500 - accuracy: 0.0000e+00\n",
            "Epoch 502/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3963099.2500 - accuracy: 0.0000e+00\n",
            "Epoch 503/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5585620.0000 - accuracy: 0.0000e+00\n",
            "Epoch 504/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3555073.7500 - accuracy: 0.0000e+00\n",
            "Epoch 505/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4367167.0000 - accuracy: 0.0000e+00\n",
            "Epoch 506/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3361253.5000 - accuracy: 0.0000e+00\n",
            "Epoch 507/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3612834.0000 - accuracy: 0.0000e+00\n",
            "Epoch 508/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3819424.2500 - accuracy: 0.0000e+00\n",
            "Epoch 509/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4853632.5000 - accuracy: 0.0000e+00\n",
            "Epoch 510/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4761225.5000 - accuracy: 0.0000e+00\n",
            "Epoch 511/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 4506379.5000 - accuracy: 0.0000e+00\n",
            "Epoch 512/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3210050.2500 - accuracy: 0.0000e+00\n",
            "Epoch 513/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 4292736.0000 - accuracy: 0.0000e+00\n",
            "Epoch 514/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 3995027.2500 - accuracy: 0.0000e+00\n",
            "Epoch 515/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 3586413.7500 - accuracy: 0.0000e+00\n",
            "Epoch 516/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 4048641.0000 - accuracy: 3.0367e-04\n",
            "Epoch 517/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3653992.7500 - accuracy: 0.0000e+00\n",
            "Epoch 518/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3280052.7500 - accuracy: 3.0367e-04\n",
            "Epoch 519/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3921722.0000 - accuracy: 0.0000e+00\n",
            "Epoch 520/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3671165.2500 - accuracy: 0.0000e+00\n",
            "Epoch 521/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3502087.2500 - accuracy: 0.0000e+00\n",
            "Epoch 522/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3881490.7500 - accuracy: 0.0000e+00\n",
            "Epoch 523/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4607890.0000 - accuracy: 3.0367e-04\n",
            "Epoch 524/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3899303.0000 - accuracy: 0.0000e+00\n",
            "Epoch 525/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3791213.0000 - accuracy: 0.0000e+00\n",
            "Epoch 526/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3219642.5000 - accuracy: 0.0000e+00\n",
            "Epoch 527/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3494844.0000 - accuracy: 0.0000e+00\n",
            "Epoch 528/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3698958.7500 - accuracy: 0.0000e+00\n",
            "Epoch 529/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 5633390.0000 - accuracy: 0.0000e+00\n",
            "Epoch 530/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 4639143.0000 - accuracy: 0.0000e+00\n",
            "Epoch 531/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 3830646.0000 - accuracy: 0.0000e+00\n",
            "Epoch 532/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4072266.7500 - accuracy: 0.0000e+00\n",
            "Epoch 533/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3450825.0000 - accuracy: 0.0000e+00\n",
            "Epoch 534/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3588330.2500 - accuracy: 0.0000e+00\n",
            "Epoch 535/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3329041.0000 - accuracy: 0.0000e+00\n",
            "Epoch 536/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3830858.0000 - accuracy: 0.0000e+00\n",
            "Epoch 537/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3985706.0000 - accuracy: 0.0000e+00\n",
            "Epoch 538/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3579753.7500 - accuracy: 0.0000e+00\n",
            "Epoch 539/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3920541.2500 - accuracy: 0.0000e+00\n",
            "Epoch 540/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3561017.0000 - accuracy: 0.0000e+00\n",
            "Epoch 541/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4021152.5000 - accuracy: 0.0000e+00\n",
            "Epoch 542/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4402697.0000 - accuracy: 0.0000e+00\n",
            "Epoch 543/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 3726530.0000 - accuracy: 0.0000e+00\n",
            "Epoch 544/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3659245.5000 - accuracy: 0.0000e+00\n",
            "Epoch 545/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 3234100.7500 - accuracy: 0.0000e+00\n",
            "Epoch 546/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3720530.0000 - accuracy: 0.0000e+00\n",
            "Epoch 547/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3688701.7500 - accuracy: 0.0000e+00\n",
            "Epoch 548/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3675396.2500 - accuracy: 0.0000e+00\n",
            "Epoch 549/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4473322.5000 - accuracy: 0.0000e+00\n",
            "Epoch 550/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4636716.0000 - accuracy: 0.0000e+00\n",
            "Epoch 551/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4387065.5000 - accuracy: 3.0367e-04\n",
            "Epoch 552/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4512311.5000 - accuracy: 0.0000e+00\n",
            "Epoch 553/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4059593.5000 - accuracy: 0.0000e+00\n",
            "Epoch 554/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4212026.0000 - accuracy: 0.0000e+00\n",
            "Epoch 555/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4814695.5000 - accuracy: 0.0000e+00\n",
            "Epoch 556/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3882440.5000 - accuracy: 0.0000e+00\n",
            "Epoch 557/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3726807.0000 - accuracy: 0.0000e+00\n",
            "Epoch 558/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3542360.0000 - accuracy: 0.0000e+00\n",
            "Epoch 559/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3520087.2500 - accuracy: 0.0000e+00\n",
            "Epoch 560/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3782644.7500 - accuracy: 0.0000e+00\n",
            "Epoch 561/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2898642.7500 - accuracy: 0.0000e+00\n",
            "Epoch 562/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3648328.5000 - accuracy: 0.0000e+00\n",
            "Epoch 563/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4554272.0000 - accuracy: 0.0000e+00\n",
            "Epoch 564/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 4482923.0000 - accuracy: 0.0000e+00\n",
            "Epoch 565/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3107560.7500 - accuracy: 0.0000e+00\n",
            "Epoch 566/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3288796.0000 - accuracy: 0.0000e+00\n",
            "Epoch 567/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4300374.5000 - accuracy: 0.0000e+00\n",
            "Epoch 568/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4010023.7500 - accuracy: 0.0000e+00\n",
            "Epoch 569/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3648796.7500 - accuracy: 3.0367e-04\n",
            "Epoch 570/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3621801.2500 - accuracy: 0.0000e+00\n",
            "Epoch 571/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3164750.7500 - accuracy: 0.0000e+00\n",
            "Epoch 572/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3540039.5000 - accuracy: 0.0000e+00\n",
            "Epoch 573/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3281780.0000 - accuracy: 0.0000e+00\n",
            "Epoch 574/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3201994.0000 - accuracy: 0.0000e+00\n",
            "Epoch 575/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 4506533.5000 - accuracy: 0.0000e+00\n",
            "Epoch 576/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3946992.0000 - accuracy: 0.0000e+00\n",
            "Epoch 577/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3779177.0000 - accuracy: 0.0000e+00\n",
            "Epoch 578/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5351708.0000 - accuracy: 0.0000e+00\n",
            "Epoch 579/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3762705.2500 - accuracy: 0.0000e+00\n",
            "Epoch 580/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3533381.7500 - accuracy: 0.0000e+00\n",
            "Epoch 581/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3502812.2500 - accuracy: 0.0000e+00\n",
            "Epoch 582/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4177391.2500 - accuracy: 0.0000e+00\n",
            "Epoch 583/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4560025.5000 - accuracy: 0.0000e+00\n",
            "Epoch 584/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4193203.7500 - accuracy: 0.0000e+00\n",
            "Epoch 585/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3132051.7500 - accuracy: 0.0000e+00\n",
            "Epoch 586/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3077593.2500 - accuracy: 0.0000e+00\n",
            "Epoch 587/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3492810.2500 - accuracy: 0.0000e+00\n",
            "Epoch 588/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3428649.0000 - accuracy: 0.0000e+00\n",
            "Epoch 589/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3552429.7500 - accuracy: 0.0000e+00\n",
            "Epoch 590/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 3877774.7500 - accuracy: 0.0000e+00\n",
            "Epoch 591/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3870643.5000 - accuracy: 0.0000e+00\n",
            "Epoch 592/1000\n",
            "103/103 [==============================] - 1s 7ms/step - loss: 3470098.7500 - accuracy: 0.0000e+00\n",
            "Epoch 593/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3522570.0000 - accuracy: 0.0000e+00\n",
            "Epoch 594/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 5280919.0000 - accuracy: 0.0000e+00\n",
            "Epoch 595/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3557410.0000 - accuracy: 0.0000e+00\n",
            "Epoch 596/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3079142.2500 - accuracy: 0.0000e+00\n",
            "Epoch 597/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3279666.2500 - accuracy: 0.0000e+00\n",
            "Epoch 598/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3147691.5000 - accuracy: 0.0000e+00\n",
            "Epoch 599/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3919512.7500 - accuracy: 0.0000e+00\n",
            "Epoch 600/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2976603.5000 - accuracy: 0.0000e+00\n",
            "Epoch 601/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3542668.0000 - accuracy: 0.0000e+00\n",
            "Epoch 602/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2877299.5000 - accuracy: 0.0000e+00\n",
            "Epoch 603/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3932203.7500 - accuracy: 0.0000e+00\n",
            "Epoch 604/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 4382400.5000 - accuracy: 0.0000e+00\n",
            "Epoch 605/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3411275.7500 - accuracy: 0.0000e+00\n",
            "Epoch 606/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3188479.7500 - accuracy: 0.0000e+00\n",
            "Epoch 607/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3820375.5000 - accuracy: 0.0000e+00\n",
            "Epoch 608/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2803502.7500 - accuracy: 0.0000e+00\n",
            "Epoch 609/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3743296.5000 - accuracy: 0.0000e+00\n",
            "Epoch 610/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3336190.7500 - accuracy: 0.0000e+00\n",
            "Epoch 611/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3934824.2500 - accuracy: 0.0000e+00\n",
            "Epoch 612/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2958983.0000 - accuracy: 0.0000e+00\n",
            "Epoch 613/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3873788.2500 - accuracy: 0.0000e+00\n",
            "Epoch 614/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4177768.0000 - accuracy: 0.0000e+00\n",
            "Epoch 615/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3762350.5000 - accuracy: 0.0000e+00\n",
            "Epoch 616/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4101105.7500 - accuracy: 6.0735e-04\n",
            "Epoch 617/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3920106.2500 - accuracy: 0.0000e+00\n",
            "Epoch 618/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3752484.7500 - accuracy: 0.0000e+00\n",
            "Epoch 619/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3757780.5000 - accuracy: 0.0000e+00\n",
            "Epoch 620/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 3995947.2500 - accuracy: 0.0000e+00\n",
            "Epoch 621/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3622461.5000 - accuracy: 0.0000e+00\n",
            "Epoch 622/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3453228.0000 - accuracy: 3.0367e-04\n",
            "Epoch 623/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3244458.2500 - accuracy: 0.0000e+00\n",
            "Epoch 624/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3138746.0000 - accuracy: 0.0000e+00\n",
            "Epoch 625/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3761980.5000 - accuracy: 0.0000e+00\n",
            "Epoch 626/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3338475.5000 - accuracy: 0.0000e+00\n",
            "Epoch 627/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3659133.0000 - accuracy: 0.0000e+00\n",
            "Epoch 628/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4382500.5000 - accuracy: 0.0000e+00\n",
            "Epoch 629/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3313854.2500 - accuracy: 0.0000e+00\n",
            "Epoch 630/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3555905.5000 - accuracy: 0.0000e+00\n",
            "Epoch 631/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3562812.0000 - accuracy: 0.0000e+00\n",
            "Epoch 632/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 4133926.7500 - accuracy: 0.0000e+00\n",
            "Epoch 633/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 4196912.5000 - accuracy: 0.0000e+00\n",
            "Epoch 634/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 4000216.2500 - accuracy: 0.0000e+00\n",
            "Epoch 635/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2714716.2500 - accuracy: 0.0000e+00\n",
            "Epoch 636/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3865216.5000 - accuracy: 0.0000e+00\n",
            "Epoch 637/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3431353.5000 - accuracy: 0.0000e+00\n",
            "Epoch 638/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3490463.7500 - accuracy: 0.0000e+00\n",
            "Epoch 639/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3389004.7500 - accuracy: 0.0000e+00\n",
            "Epoch 640/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3367603.5000 - accuracy: 0.0000e+00\n",
            "Epoch 641/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3407560.5000 - accuracy: 0.0000e+00\n",
            "Epoch 642/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3868938.5000 - accuracy: 0.0000e+00\n",
            "Epoch 643/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4246613.0000 - accuracy: 0.0000e+00\n",
            "Epoch 644/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3350258.5000 - accuracy: 0.0000e+00\n",
            "Epoch 645/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4248510.5000 - accuracy: 0.0000e+00\n",
            "Epoch 646/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3987058.5000 - accuracy: 0.0000e+00\n",
            "Epoch 647/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3344341.0000 - accuracy: 0.0000e+00\n",
            "Epoch 648/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3578431.2500 - accuracy: 0.0000e+00\n",
            "Epoch 649/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3191081.0000 - accuracy: 0.0000e+00\n",
            "Epoch 650/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2667957.7500 - accuracy: 0.0000e+00\n",
            "Epoch 651/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2990731.5000 - accuracy: 0.0000e+00\n",
            "Epoch 652/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3495619.5000 - accuracy: 0.0000e+00\n",
            "Epoch 653/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3468194.0000 - accuracy: 0.0000e+00\n",
            "Epoch 654/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3670475.2500 - accuracy: 0.0000e+00\n",
            "Epoch 655/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4293766.5000 - accuracy: 0.0000e+00\n",
            "Epoch 656/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3772918.0000 - accuracy: 0.0000e+00\n",
            "Epoch 657/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4482816.5000 - accuracy: 0.0000e+00\n",
            "Epoch 658/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3763420.7500 - accuracy: 0.0000e+00\n",
            "Epoch 659/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3074116.0000 - accuracy: 0.0000e+00\n",
            "Epoch 660/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3075644.7500 - accuracy: 0.0000e+00\n",
            "Epoch 661/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3245002.0000 - accuracy: 0.0000e+00\n",
            "Epoch 662/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3550371.2500 - accuracy: 0.0000e+00\n",
            "Epoch 663/1000\n",
            "103/103 [==============================] - 1s 12ms/step - loss: 3193114.0000 - accuracy: 0.0000e+00\n",
            "Epoch 664/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 2981666.2500 - accuracy: 0.0000e+00\n",
            "Epoch 665/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3493482.7500 - accuracy: 0.0000e+00\n",
            "Epoch 666/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2899168.0000 - accuracy: 0.0000e+00\n",
            "Epoch 667/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3212521.5000 - accuracy: 0.0000e+00\n",
            "Epoch 668/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3881719.0000 - accuracy: 0.0000e+00\n",
            "Epoch 669/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2865028.2500 - accuracy: 0.0000e+00\n",
            "Epoch 670/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3785308.2500 - accuracy: 0.0000e+00\n",
            "Epoch 671/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3916584.5000 - accuracy: 0.0000e+00\n",
            "Epoch 672/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4458561.5000 - accuracy: 0.0000e+00\n",
            "Epoch 673/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3735490.5000 - accuracy: 0.0000e+00\n",
            "Epoch 674/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3511034.5000 - accuracy: 0.0000e+00\n",
            "Epoch 675/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2574941.5000 - accuracy: 0.0000e+00\n",
            "Epoch 676/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3183776.5000 - accuracy: 0.0000e+00\n",
            "Epoch 677/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 3600265.7500 - accuracy: 0.0000e+00\n",
            "Epoch 678/1000\n",
            "103/103 [==============================] - 1s 12ms/step - loss: 3618130.2500 - accuracy: 0.0000e+00\n",
            "Epoch 679/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3372095.2500 - accuracy: 0.0000e+00\n",
            "Epoch 680/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3952783.2500 - accuracy: 0.0000e+00\n",
            "Epoch 681/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4050723.0000 - accuracy: 0.0000e+00\n",
            "Epoch 682/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3488882.5000 - accuracy: 0.0000e+00\n",
            "Epoch 683/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3365300.5000 - accuracy: 0.0000e+00\n",
            "Epoch 684/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3748896.0000 - accuracy: 0.0000e+00\n",
            "Epoch 685/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3246913.7500 - accuracy: 0.0000e+00\n",
            "Epoch 686/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3868436.5000 - accuracy: 0.0000e+00\n",
            "Epoch 687/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3718357.2500 - accuracy: 0.0000e+00\n",
            "Epoch 688/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3221422.2500 - accuracy: 0.0000e+00\n",
            "Epoch 689/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3474588.7500 - accuracy: 0.0000e+00\n",
            "Epoch 690/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3585507.2500 - accuracy: 0.0000e+00\n",
            "Epoch 691/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3442981.5000 - accuracy: 0.0000e+00\n",
            "Epoch 692/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3511960.0000 - accuracy: 3.0367e-04\n",
            "Epoch 693/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3345523.2500 - accuracy: 0.0000e+00\n",
            "Epoch 694/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3829483.0000 - accuracy: 0.0000e+00\n",
            "Epoch 695/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3638556.0000 - accuracy: 0.0000e+00\n",
            "Epoch 696/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2292468.7500 - accuracy: 0.0000e+00\n",
            "Epoch 697/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3368993.2500 - accuracy: 0.0000e+00\n",
            "Epoch 698/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3018853.0000 - accuracy: 0.0000e+00\n",
            "Epoch 699/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2889311.5000 - accuracy: 0.0000e+00\n",
            "Epoch 700/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2902425.2500 - accuracy: 0.0000e+00\n",
            "Epoch 701/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3147293.5000 - accuracy: 0.0000e+00\n",
            "Epoch 702/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3330413.0000 - accuracy: 0.0000e+00\n",
            "Epoch 703/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3289126.5000 - accuracy: 0.0000e+00\n",
            "Epoch 704/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3656720.2500 - accuracy: 0.0000e+00\n",
            "Epoch 705/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3664074.2500 - accuracy: 0.0000e+00\n",
            "Epoch 706/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 3888643.2500 - accuracy: 0.0000e+00\n",
            "Epoch 707/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3916461.7500 - accuracy: 0.0000e+00\n",
            "Epoch 708/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 2417754.7500 - accuracy: 0.0000e+00\n",
            "Epoch 709/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 3210121.5000 - accuracy: 0.0000e+00\n",
            "Epoch 710/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3142592.0000 - accuracy: 0.0000e+00\n",
            "Epoch 711/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2603266.0000 - accuracy: 0.0000e+00\n",
            "Epoch 712/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3503714.7500 - accuracy: 0.0000e+00\n",
            "Epoch 713/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3035668.7500 - accuracy: 0.0000e+00\n",
            "Epoch 714/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2915836.0000 - accuracy: 0.0000e+00\n",
            "Epoch 715/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3084804.2500 - accuracy: 0.0000e+00\n",
            "Epoch 716/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3362915.2500 - accuracy: 0.0000e+00\n",
            "Epoch 717/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2920092.5000 - accuracy: 0.0000e+00\n",
            "Epoch 718/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3124257.2500 - accuracy: 0.0000e+00\n",
            "Epoch 719/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3239925.5000 - accuracy: 0.0000e+00\n",
            "Epoch 720/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3321278.0000 - accuracy: 0.0000e+00\n",
            "Epoch 721/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 3810054.5000 - accuracy: 0.0000e+00\n",
            "Epoch 722/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3366512.7500 - accuracy: 0.0000e+00\n",
            "Epoch 723/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3750837.7500 - accuracy: 0.0000e+00\n",
            "Epoch 724/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3993459.2500 - accuracy: 0.0000e+00\n",
            "Epoch 725/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3661268.5000 - accuracy: 0.0000e+00\n",
            "Epoch 726/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2968561.0000 - accuracy: 0.0000e+00\n",
            "Epoch 727/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3109295.5000 - accuracy: 0.0000e+00\n",
            "Epoch 728/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3480494.2500 - accuracy: 0.0000e+00\n",
            "Epoch 729/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2911730.7500 - accuracy: 0.0000e+00\n",
            "Epoch 730/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2793758.7500 - accuracy: 0.0000e+00\n",
            "Epoch 731/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4570606.0000 - accuracy: 0.0000e+00\n",
            "Epoch 732/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2997078.7500 - accuracy: 0.0000e+00\n",
            "Epoch 733/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2934782.5000 - accuracy: 0.0000e+00\n",
            "Epoch 734/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4208698.0000 - accuracy: 0.0000e+00\n",
            "Epoch 735/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3279897.2500 - accuracy: 3.0367e-04\n",
            "Epoch 736/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 3360612.2500 - accuracy: 0.0000e+00\n",
            "Epoch 737/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 3354360.2500 - accuracy: 0.0000e+00\n",
            "Epoch 738/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3845712.0000 - accuracy: 0.0000e+00\n",
            "Epoch 739/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 2951919.0000 - accuracy: 0.0000e+00\n",
            "Epoch 740/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3313963.7500 - accuracy: 0.0000e+00\n",
            "Epoch 741/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3104043.7500 - accuracy: 0.0000e+00\n",
            "Epoch 742/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3751686.5000 - accuracy: 0.0000e+00\n",
            "Epoch 743/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3349773.5000 - accuracy: 0.0000e+00\n",
            "Epoch 744/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2480085.5000 - accuracy: 0.0000e+00\n",
            "Epoch 745/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3126899.0000 - accuracy: 0.0000e+00\n",
            "Epoch 746/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4283465.0000 - accuracy: 0.0000e+00\n",
            "Epoch 747/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3343589.2500 - accuracy: 0.0000e+00\n",
            "Epoch 748/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3681997.7500 - accuracy: 0.0000e+00\n",
            "Epoch 749/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3003810.0000 - accuracy: 0.0000e+00\n",
            "Epoch 750/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3111608.2500 - accuracy: 0.0000e+00\n",
            "Epoch 751/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3141388.0000 - accuracy: 0.0000e+00\n",
            "Epoch 752/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 2833005.0000 - accuracy: 0.0000e+00\n",
            "Epoch 753/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 2994354.5000 - accuracy: 0.0000e+00\n",
            "Epoch 754/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 3546116.7500 - accuracy: 0.0000e+00\n",
            "Epoch 755/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2737465.5000 - accuracy: 0.0000e+00\n",
            "Epoch 756/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 4300881.0000 - accuracy: 0.0000e+00\n",
            "Epoch 757/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3700294.7500 - accuracy: 0.0000e+00\n",
            "Epoch 758/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2694558.0000 - accuracy: 0.0000e+00\n",
            "Epoch 759/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4066444.2500 - accuracy: 0.0000e+00\n",
            "Epoch 760/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3794474.7500 - accuracy: 0.0000e+00\n",
            "Epoch 761/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3454075.7500 - accuracy: 0.0000e+00\n",
            "Epoch 762/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3476751.2500 - accuracy: 0.0000e+00\n",
            "Epoch 763/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2938576.7500 - accuracy: 0.0000e+00\n",
            "Epoch 764/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3036495.7500 - accuracy: 0.0000e+00\n",
            "Epoch 765/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3679017.7500 - accuracy: 0.0000e+00\n",
            "Epoch 766/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3852401.7500 - accuracy: 0.0000e+00\n",
            "Epoch 767/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3703899.7500 - accuracy: 0.0000e+00\n",
            "Epoch 768/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 2987718.2500 - accuracy: 0.0000e+00\n",
            "Epoch 769/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 2746554.5000 - accuracy: 0.0000e+00\n",
            "Epoch 770/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2911612.5000 - accuracy: 0.0000e+00\n",
            "Epoch 771/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3604636.7500 - accuracy: 0.0000e+00\n",
            "Epoch 772/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3088524.5000 - accuracy: 0.0000e+00\n",
            "Epoch 773/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3388506.2500 - accuracy: 0.0000e+00\n",
            "Epoch 774/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4164648.7500 - accuracy: 0.0000e+00\n",
            "Epoch 775/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 4148133.2500 - accuracy: 0.0000e+00\n",
            "Epoch 776/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2988143.0000 - accuracy: 0.0000e+00\n",
            "Epoch 777/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2795182.0000 - accuracy: 0.0000e+00\n",
            "Epoch 778/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3113451.0000 - accuracy: 0.0000e+00\n",
            "Epoch 779/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2433432.2500 - accuracy: 0.0000e+00\n",
            "Epoch 780/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2561722.5000 - accuracy: 0.0000e+00\n",
            "Epoch 781/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 2923649.2500 - accuracy: 0.0000e+00\n",
            "Epoch 782/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3042697.7500 - accuracy: 0.0000e+00\n",
            "Epoch 783/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3325369.2500 - accuracy: 0.0000e+00\n",
            "Epoch 784/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 3223800.2500 - accuracy: 0.0000e+00\n",
            "Epoch 785/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2910238.5000 - accuracy: 0.0000e+00\n",
            "Epoch 786/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2489358.0000 - accuracy: 0.0000e+00\n",
            "Epoch 787/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3629507.2500 - accuracy: 0.0000e+00\n",
            "Epoch 788/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3597668.2500 - accuracy: 0.0000e+00\n",
            "Epoch 789/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2881647.7500 - accuracy: 0.0000e+00\n",
            "Epoch 790/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2813656.2500 - accuracy: 0.0000e+00\n",
            "Epoch 791/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2514625.5000 - accuracy: 0.0000e+00\n",
            "Epoch 792/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3496130.7500 - accuracy: 0.0000e+00\n",
            "Epoch 793/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3311579.2500 - accuracy: 0.0000e+00\n",
            "Epoch 794/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3117141.7500 - accuracy: 0.0000e+00\n",
            "Epoch 795/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2762136.5000 - accuracy: 0.0000e+00\n",
            "Epoch 796/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3187462.2500 - accuracy: 0.0000e+00\n",
            "Epoch 797/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3417764.2500 - accuracy: 0.0000e+00\n",
            "Epoch 798/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 2770396.0000 - accuracy: 0.0000e+00\n",
            "Epoch 799/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2873275.2500 - accuracy: 3.0367e-04\n",
            "Epoch 800/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3411617.2500 - accuracy: 0.0000e+00\n",
            "Epoch 801/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 4337501.5000 - accuracy: 0.0000e+00\n",
            "Epoch 802/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4074781.5000 - accuracy: 0.0000e+00\n",
            "Epoch 803/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3154519.2500 - accuracy: 0.0000e+00\n",
            "Epoch 804/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3528784.7500 - accuracy: 3.0367e-04\n",
            "Epoch 805/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3031465.0000 - accuracy: 0.0000e+00\n",
            "Epoch 806/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3168031.7500 - accuracy: 0.0000e+00\n",
            "Epoch 807/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3026808.0000 - accuracy: 0.0000e+00\n",
            "Epoch 808/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3048486.7500 - accuracy: 0.0000e+00\n",
            "Epoch 809/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3108929.2500 - accuracy: 0.0000e+00\n",
            "Epoch 810/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2577074.7500 - accuracy: 0.0000e+00\n",
            "Epoch 811/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 2420258.7500 - accuracy: 0.0000e+00\n",
            "Epoch 812/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 2740107.7500 - accuracy: 0.0000e+00\n",
            "Epoch 813/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3040015.0000 - accuracy: 0.0000e+00\n",
            "Epoch 814/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2958857.2500 - accuracy: 0.0000e+00\n",
            "Epoch 815/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2929300.2500 - accuracy: 0.0000e+00\n",
            "Epoch 816/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2944132.5000 - accuracy: 0.0000e+00\n",
            "Epoch 817/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3542680.7500 - accuracy: 0.0000e+00\n",
            "Epoch 818/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3169621.5000 - accuracy: 0.0000e+00\n",
            "Epoch 819/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3122312.7500 - accuracy: 0.0000e+00\n",
            "Epoch 820/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3441211.2500 - accuracy: 0.0000e+00\n",
            "Epoch 821/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3280080.2500 - accuracy: 0.0000e+00\n",
            "Epoch 822/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2618174.2500 - accuracy: 0.0000e+00\n",
            "Epoch 823/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3114300.5000 - accuracy: 0.0000e+00\n",
            "Epoch 824/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3093932.7500 - accuracy: 0.0000e+00\n",
            "Epoch 825/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 3360167.0000 - accuracy: 0.0000e+00\n",
            "Epoch 826/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 2715120.5000 - accuracy: 0.0000e+00\n",
            "Epoch 827/1000\n",
            "103/103 [==============================] - 1s 12ms/step - loss: 3548641.7500 - accuracy: 0.0000e+00\n",
            "Epoch 828/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 2389900.0000 - accuracy: 0.0000e+00\n",
            "Epoch 829/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3219624.0000 - accuracy: 0.0000e+00\n",
            "Epoch 830/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3520944.0000 - accuracy: 3.0367e-04\n",
            "Epoch 831/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3257602.0000 - accuracy: 0.0000e+00\n",
            "Epoch 832/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3569534.2500 - accuracy: 0.0000e+00\n",
            "Epoch 833/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2814761.5000 - accuracy: 0.0000e+00\n",
            "Epoch 834/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2819334.2500 - accuracy: 0.0000e+00\n",
            "Epoch 835/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3026575.7500 - accuracy: 0.0000e+00\n",
            "Epoch 836/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2717785.7500 - accuracy: 0.0000e+00\n",
            "Epoch 837/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2890806.5000 - accuracy: 0.0000e+00\n",
            "Epoch 838/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2644179.2500 - accuracy: 0.0000e+00\n",
            "Epoch 839/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 4325236.0000 - accuracy: 0.0000e+00\n",
            "Epoch 840/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 4070444.7500 - accuracy: 0.0000e+00\n",
            "Epoch 841/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 2650873.5000 - accuracy: 0.0000e+00\n",
            "Epoch 842/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3357220.2500 - accuracy: 3.0367e-04\n",
            "Epoch 843/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 2790362.0000 - accuracy: 0.0000e+00\n",
            "Epoch 844/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2812693.0000 - accuracy: 0.0000e+00\n",
            "Epoch 845/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2673123.7500 - accuracy: 0.0000e+00\n",
            "Epoch 846/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3241241.5000 - accuracy: 0.0000e+00\n",
            "Epoch 847/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2559045.7500 - accuracy: 0.0000e+00\n",
            "Epoch 848/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2465613.0000 - accuracy: 0.0000e+00\n",
            "Epoch 849/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3357854.2500 - accuracy: 3.0367e-04\n",
            "Epoch 850/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2887111.5000 - accuracy: 0.0000e+00\n",
            "Epoch 851/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3066181.0000 - accuracy: 0.0000e+00\n",
            "Epoch 852/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3299238.7500 - accuracy: 0.0000e+00\n",
            "Epoch 853/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2892372.0000 - accuracy: 0.0000e+00\n",
            "Epoch 854/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3856140.5000 - accuracy: 0.0000e+00\n",
            "Epoch 855/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3416816.7500 - accuracy: 0.0000e+00\n",
            "Epoch 856/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3301556.2500 - accuracy: 0.0000e+00\n",
            "Epoch 857/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3322036.2500 - accuracy: 0.0000e+00\n",
            "Epoch 858/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3665000.5000 - accuracy: 0.0000e+00\n",
            "Epoch 859/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2601072.2500 - accuracy: 0.0000e+00\n",
            "Epoch 860/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3034270.5000 - accuracy: 0.0000e+00\n",
            "Epoch 861/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3752497.2500 - accuracy: 0.0000e+00\n",
            "Epoch 862/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3527858.2500 - accuracy: 0.0000e+00\n",
            "Epoch 863/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2645811.7500 - accuracy: 0.0000e+00\n",
            "Epoch 864/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2821969.7500 - accuracy: 0.0000e+00\n",
            "Epoch 865/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3289312.0000 - accuracy: 0.0000e+00\n",
            "Epoch 866/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2675860.0000 - accuracy: 0.0000e+00\n",
            "Epoch 867/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3473109.2500 - accuracy: 0.0000e+00\n",
            "Epoch 868/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 4947267.0000 - accuracy: 0.0000e+00\n",
            "Epoch 869/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 2844675.5000 - accuracy: 0.0000e+00\n",
            "Epoch 870/1000\n",
            "103/103 [==============================] - 1s 12ms/step - loss: 2824843.2500 - accuracy: 0.0000e+00\n",
            "Epoch 871/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3396703.7500 - accuracy: 0.0000e+00\n",
            "Epoch 872/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 3013042.5000 - accuracy: 0.0000e+00\n",
            "Epoch 873/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3571215.0000 - accuracy: 0.0000e+00\n",
            "Epoch 874/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3961635.0000 - accuracy: 0.0000e+00\n",
            "Epoch 875/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3465274.2500 - accuracy: 0.0000e+00\n",
            "Epoch 876/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2354282.2500 - accuracy: 0.0000e+00\n",
            "Epoch 877/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3253223.5000 - accuracy: 0.0000e+00\n",
            "Epoch 878/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3345177.5000 - accuracy: 0.0000e+00\n",
            "Epoch 879/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2805908.7500 - accuracy: 0.0000e+00\n",
            "Epoch 880/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2507422.5000 - accuracy: 0.0000e+00\n",
            "Epoch 881/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2305237.7500 - accuracy: 3.0367e-04\n",
            "Epoch 882/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3275638.7500 - accuracy: 0.0000e+00\n",
            "Epoch 883/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3381526.5000 - accuracy: 0.0000e+00\n",
            "Epoch 884/1000\n",
            "103/103 [==============================] - 1s 12ms/step - loss: 3002892.5000 - accuracy: 0.0000e+00\n",
            "Epoch 885/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 2595540.5000 - accuracy: 0.0000e+00\n",
            "Epoch 886/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 2604865.5000 - accuracy: 3.0367e-04\n",
            "Epoch 887/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 3332861.5000 - accuracy: 3.0367e-04\n",
            "Epoch 888/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2886879.5000 - accuracy: 0.0000e+00\n",
            "Epoch 889/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2994998.2500 - accuracy: 0.0000e+00\n",
            "Epoch 890/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2494050.5000 - accuracy: 0.0000e+00\n",
            "Epoch 891/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 4045203.7500 - accuracy: 3.0367e-04\n",
            "Epoch 892/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2710792.2500 - accuracy: 0.0000e+00\n",
            "Epoch 893/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2500725.5000 - accuracy: 0.0000e+00\n",
            "Epoch 894/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3514104.5000 - accuracy: 0.0000e+00\n",
            "Epoch 895/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3520882.7500 - accuracy: 0.0000e+00\n",
            "Epoch 896/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3736815.7500 - accuracy: 0.0000e+00\n",
            "Epoch 897/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2854992.5000 - accuracy: 0.0000e+00\n",
            "Epoch 898/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 3094456.7500 - accuracy: 0.0000e+00\n",
            "Epoch 899/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 4424809.0000 - accuracy: 0.0000e+00\n",
            "Epoch 900/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3321957.0000 - accuracy: 0.0000e+00\n",
            "Epoch 901/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 2983437.2500 - accuracy: 0.0000e+00\n",
            "Epoch 902/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3268218.0000 - accuracy: 0.0000e+00\n",
            "Epoch 903/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3435661.2500 - accuracy: 0.0000e+00\n",
            "Epoch 904/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3681420.2500 - accuracy: 0.0000e+00\n",
            "Epoch 905/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2931342.5000 - accuracy: 0.0000e+00\n",
            "Epoch 906/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2660475.5000 - accuracy: 0.0000e+00\n",
            "Epoch 907/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2929049.7500 - accuracy: 0.0000e+00\n",
            "Epoch 908/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3294328.2500 - accuracy: 0.0000e+00\n",
            "Epoch 909/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2800668.2500 - accuracy: 0.0000e+00\n",
            "Epoch 910/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3125843.7500 - accuracy: 0.0000e+00\n",
            "Epoch 911/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2743414.5000 - accuracy: 0.0000e+00\n",
            "Epoch 912/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3010555.7500 - accuracy: 0.0000e+00\n",
            "Epoch 913/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3140819.5000 - accuracy: 0.0000e+00\n",
            "Epoch 914/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3949542.0000 - accuracy: 0.0000e+00\n",
            "Epoch 915/1000\n",
            "103/103 [==============================] - 1s 12ms/step - loss: 3043155.0000 - accuracy: 0.0000e+00\n",
            "Epoch 916/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 2747050.2500 - accuracy: 0.0000e+00\n",
            "Epoch 917/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3052686.0000 - accuracy: 0.0000e+00\n",
            "Epoch 918/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2498501.5000 - accuracy: 0.0000e+00\n",
            "Epoch 919/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2277591.2500 - accuracy: 0.0000e+00\n",
            "Epoch 920/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2452026.0000 - accuracy: 0.0000e+00\n",
            "Epoch 921/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2497133.7500 - accuracy: 0.0000e+00\n",
            "Epoch 922/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2692525.2500 - accuracy: 0.0000e+00\n",
            "Epoch 923/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2780506.0000 - accuracy: 0.0000e+00\n",
            "Epoch 924/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2676750.0000 - accuracy: 0.0000e+00\n",
            "Epoch 925/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3927721.0000 - accuracy: 0.0000e+00\n",
            "Epoch 926/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3371134.2500 - accuracy: 0.0000e+00\n",
            "Epoch 927/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2663038.5000 - accuracy: 0.0000e+00\n",
            "Epoch 928/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 2328184.7500 - accuracy: 0.0000e+00\n",
            "Epoch 929/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3161562.5000 - accuracy: 3.0367e-04\n",
            "Epoch 930/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 2868944.7500 - accuracy: 0.0000e+00\n",
            "Epoch 931/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3199552.2500 - accuracy: 0.0000e+00\n",
            "Epoch 932/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3238150.2500 - accuracy: 0.0000e+00\n",
            "Epoch 933/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2785082.5000 - accuracy: 3.0367e-04\n",
            "Epoch 934/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3812988.0000 - accuracy: 9.1102e-04\n",
            "Epoch 935/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2917963.0000 - accuracy: 0.0000e+00\n",
            "Epoch 936/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3507146.2500 - accuracy: 0.0000e+00\n",
            "Epoch 937/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3919024.7500 - accuracy: 0.0000e+00\n",
            "Epoch 938/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3818143.7500 - accuracy: 0.0000e+00\n",
            "Epoch 939/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2910842.2500 - accuracy: 0.0000e+00\n",
            "Epoch 940/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2936039.0000 - accuracy: 0.0000e+00\n",
            "Epoch 941/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2634624.5000 - accuracy: 0.0000e+00\n",
            "Epoch 942/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2471177.0000 - accuracy: 0.0000e+00\n",
            "Epoch 943/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 2328552.2500 - accuracy: 0.0000e+00\n",
            "Epoch 944/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 2833427.0000 - accuracy: 0.0000e+00\n",
            "Epoch 945/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 2768352.5000 - accuracy: 0.0000e+00\n",
            "Epoch 946/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 2585349.0000 - accuracy: 0.0000e+00\n",
            "Epoch 947/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2472507.2500 - accuracy: 0.0000e+00\n",
            "Epoch 948/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3277744.7500 - accuracy: 0.0000e+00\n",
            "Epoch 949/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2574099.5000 - accuracy: 0.0000e+00\n",
            "Epoch 950/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2805932.5000 - accuracy: 0.0000e+00\n",
            "Epoch 951/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3353479.0000 - accuracy: 0.0000e+00\n",
            "Epoch 952/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 4068620.7500 - accuracy: 0.0000e+00\n",
            "Epoch 953/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3316189.0000 - accuracy: 0.0000e+00\n",
            "Epoch 954/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2977163.5000 - accuracy: 0.0000e+00\n",
            "Epoch 955/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2997776.7500 - accuracy: 0.0000e+00\n",
            "Epoch 956/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3336299.5000 - accuracy: 0.0000e+00\n",
            "Epoch 957/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 3295030.7500 - accuracy: 0.0000e+00\n",
            "Epoch 958/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 2656059.5000 - accuracy: 0.0000e+00\n",
            "Epoch 959/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 2539162.7500 - accuracy: 0.0000e+00\n",
            "Epoch 960/1000\n",
            "103/103 [==============================] - 1s 12ms/step - loss: 2429001.7500 - accuracy: 0.0000e+00\n",
            "Epoch 961/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 2623819.2500 - accuracy: 0.0000e+00\n",
            "Epoch 962/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3025685.0000 - accuracy: 0.0000e+00\n",
            "Epoch 963/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3544523.5000 - accuracy: 3.0367e-04\n",
            "Epoch 964/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3330247.0000 - accuracy: 0.0000e+00\n",
            "Epoch 965/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3296166.7500 - accuracy: 0.0000e+00\n",
            "Epoch 966/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 4937528.5000 - accuracy: 0.0000e+00\n",
            "Epoch 967/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3017969.5000 - accuracy: 0.0000e+00\n",
            "Epoch 968/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2795572.2500 - accuracy: 0.0000e+00\n",
            "Epoch 969/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2542013.7500 - accuracy: 0.0000e+00\n",
            "Epoch 970/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2882700.2500 - accuracy: 0.0000e+00\n",
            "Epoch 971/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2809359.0000 - accuracy: 0.0000e+00\n",
            "Epoch 972/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 2744792.2500 - accuracy: 0.0000e+00\n",
            "Epoch 973/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 2594774.7500 - accuracy: 3.0367e-04\n",
            "Epoch 974/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 2353208.2500 - accuracy: 0.0000e+00\n",
            "Epoch 975/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3081737.5000 - accuracy: 0.0000e+00\n",
            "Epoch 976/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 3175764.5000 - accuracy: 3.0367e-04\n",
            "Epoch 977/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2792577.0000 - accuracy: 3.0367e-04\n",
            "Epoch 978/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2611052.5000 - accuracy: 0.0000e+00\n",
            "Epoch 979/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3389814.5000 - accuracy: 0.0000e+00\n",
            "Epoch 980/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2985905.0000 - accuracy: 0.0000e+00\n",
            "Epoch 981/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2865540.0000 - accuracy: 0.0000e+00\n",
            "Epoch 982/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2163120.5000 - accuracy: 0.0000e+00\n",
            "Epoch 983/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2382400.0000 - accuracy: 0.0000e+00\n",
            "Epoch 984/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3138880.5000 - accuracy: 0.0000e+00\n",
            "Epoch 985/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3167055.7500 - accuracy: 0.0000e+00\n",
            "Epoch 986/1000\n",
            "103/103 [==============================] - 1s 8ms/step - loss: 2017818.2500 - accuracy: 0.0000e+00\n",
            "Epoch 987/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 2195537.7500 - accuracy: 0.0000e+00\n",
            "Epoch 988/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 2572152.2500 - accuracy: 0.0000e+00\n",
            "Epoch 989/1000\n",
            "103/103 [==============================] - 1s 11ms/step - loss: 3203430.5000 - accuracy: 0.0000e+00\n",
            "Epoch 990/1000\n",
            "103/103 [==============================] - 1s 10ms/step - loss: 3643904.5000 - accuracy: 0.0000e+00\n",
            "Epoch 991/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2718160.2500 - accuracy: 0.0000e+00\n",
            "Epoch 992/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2483309.7500 - accuracy: 0.0000e+00\n",
            "Epoch 993/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2952423.7500 - accuracy: 0.0000e+00\n",
            "Epoch 994/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2549110.0000 - accuracy: 0.0000e+00\n",
            "Epoch 995/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3372527.2500 - accuracy: 0.0000e+00\n",
            "Epoch 996/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 3084213.7500 - accuracy: 0.0000e+00\n",
            "Epoch 997/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2463488.0000 - accuracy: 0.0000e+00\n",
            "Epoch 998/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2498389.5000 - accuracy: 0.0000e+00\n",
            "Epoch 999/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2472178.7500 - accuracy: 0.0000e+00\n",
            "Epoch 1000/1000\n",
            "103/103 [==============================] - 1s 9ms/step - loss: 2471392.5000 - accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45/45 [==============================] - 0s 2ms/step - loss: 12540696.0000 - accuracy: 0.0000e+00\n",
            "45/45 [==============================] - 0s 2ms/step\n",
            "[12540696.0, 0.0]\n",
            "12540694.792262707\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Name         Score           MSE\n",
              "0  DL_relu  1.254070e+07  1.254069e+07\n",
              "1       rf  5.230624e-01  1.317658e+07\n",
              "2       dt  3.115298e-01  1.902069e+07\n",
              "3       lr  2.626719e-01  2.037051e+07\n",
              "4       ab  1.377055e-01  2.382302e+07\n",
              "5      svr -1.197486e-01  3.093582e+07"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a6a5a39-24d6-4709-b80f-4e9e932c67b3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Score</th>\n",
              "      <th>MSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DL_relu</td>\n",
              "      <td>1.254070e+07</td>\n",
              "      <td>1.254069e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rf</td>\n",
              "      <td>5.230624e-01</td>\n",
              "      <td>1.317658e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dt</td>\n",
              "      <td>3.115298e-01</td>\n",
              "      <td>1.902069e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lr</td>\n",
              "      <td>2.626719e-01</td>\n",
              "      <td>2.037051e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ab</td>\n",
              "      <td>1.377055e-01</td>\n",
              "      <td>2.382302e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>svr</td>\n",
              "      <td>-1.197486e-01</td>\n",
              "      <td>3.093582e+07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a6a5a39-24d6-4709-b80f-4e9e932c67b3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6a6a5a39-24d6-4709-b80f-4e9e932c67b3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6a6a5a39-24d6-4709-b80f-4e9e932c67b3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "models = [['lr', LinearRegression, {}],\n",
        "          ['dt', DecisionTreeRegressor, {}],\n",
        "          ['ab', AdaBoostRegressor, {}],\n",
        "          ['rf', RandomForestRegressor, {'n_estimators':10}],\n",
        "          ['svr', SVR, {}]\n",
        "        ]\n",
        "for i in range(len(models)):\n",
        "    model = models[i][1](**models[i][2])\n",
        "    model.fit(x_train, y_train)\n",
        "    score = model.score(x_test, y_test)\n",
        "    mse = mean_squared_error(y_test, model.predict(x_test))\n",
        "    models[i].extend([score, mse])\n",
        "    print(f'{models[i][0]}:')\n",
        "    print(f'Score: {score}')\n",
        "    print(f'MSE: {mse}')\n",
        "    print('--------------------------------')\n",
        "models_table = pd.DataFrame(models, columns=['Name', 'Model', 'Params', 'Score', 'MSE'])\\\n",
        "    .sort_values('MSE')\\\n",
        "    .reset_index(drop=True)\n",
        "\n",
        "model1 = Sequential([\n",
        "    Dense(1000, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(500, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(1)\n",
        "])\n",
        "model1.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model1.fit(x_train, y_train, epochs=1000)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.show()\n",
        "\n",
        "score = model1.evaluate(x_test, y_test)\n",
        "mse = mean_squared_error(y_test, model1.predict(x_test))\n",
        "print(score)\n",
        "print(mse)\n",
        "\n",
        "models_table.loc[len(models_table)] = ['DL_relu', model1, '', score[0], mse]\n",
        "# Final data\n",
        "models_table = models_table\\\n",
        "    .sort_values('MSE')\\\n",
        "    .reset_index(drop=True)\n",
        "models_table.drop(['Model', 'Params'], axis=1)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}